{
  "MichaelBrown": [
    {
        "question": "Why is 'red spots over body' a strong indicator for diseases like Chicken Pox and Acne in Michael's case?",
        "options": [
            "Because it is linked to of skin-related diseases in training data",
            "Because Random Forest directly assigns specialists based on symptoms",
            "Because all red symptoms map to Dermatologists",
            "Because softmax only supports Dermatology labels"
        ],
        "answer": "1"
    },
    {
        "question": "Why is Chicken pox more likely than Acne or Hepatitis C for Michael?",
        "options": [
            "Because multiple symptoms like skin rash and red spots commonly co-occur in Chicken pox cases in the training data",
            "Because Hepatitis C is always assigned lower priority",
            "Because training data does not contain any information about Acne and Hepatitis C",
            "Because one-hot encoding removed the other options"
        ],
        "answer": "1"
    },
    {
        "question": "Why would removing 'skin_rash' from Michael's symptoms affect the chance of a Dermatologist being recommended?",
        "options": [
            "Because it weakens the model's confidence in skin diseases, which are mapped to Dermatologists",
            "Because it causes the softmax to ignore skin-related features",
            "Because Random Forest directly removes specialist labels",
            "Because one-hot encoding breaks"
        ],
        "answer": "1"
    },
    {
        "question": "Why does the model show Acne as the second prediction even though its probability is much lower than Chicken pox?",
        "options": [
            "Because it's still the second most likely diagnosis based on Michael's symptoms",
            "Because the system must alphabetize the outputs",
            "Because Acne is preferred in absence of CRP values",
            "Because Dermatologist needs at least two diseases"
        ],
        "answer": "1"
    },
    {
        "question": "Why might Hepatitis C receive a low but nonzero probability in Michael's output?",
        "options": [
            "Because symptoms like fatigue and lethargy partially match cases labeled as Hepatitis C in training",
            "Because softmax enforces a fixed minimum probability",
            "Because all liver conditions are boosted",
            "Because the model assigns random minimum probabilities to all classes (diseases)"
        ],
        "answer": "1"
    },
    {
      "question": "What binary vector entry corresponds to the symptom 'fatigue'?",
      "options": [
        "1 if fatigue is present, 0 if absent",
        "The average fatigue score across trees",
        "The softmaxed probability of fatigue",
        "A continuous lab value"
      ],
      "answer": "1"
    },
    {
        "question": "Why might adding 'itching' to Michael's symptoms further increase Chicken pox probability?",
        "options": [
            "Because itching often co-occurs with Chicken pox in training data and reinforces its path in decision trees",
            "Because softmax favors longer symptom vectors and adding any random symptoms will increase probability scores of previously predicted diseases.",
            "Because itching encodes probability weights",
            "Because Hepatologist is suppressed"
        ],
        "answer": "1"
    },
    {
      "question": "What is the primary reason for using a Random Forest classifier as the disease prediction model in this system?",
      "options": [
        "To take advantage of the ensemble method's ability to reduce variance and improve overall performance",
        "To handle high-dimensional symptom data and reduce overfitting",
        "To provide a simple, interpretable model for disease prediction",
        "To incorporate prior knowledge about disease-symptom relationships into the model"
      ],
      "answer": "1"
    },
    {
        "question": "Why does the model not recommend a Cardiologist for Michael despite reporting fatigue?",
        "options": [
            "Because model considers all input symptoms to provide output and fatigue is an overlapping symptom with several diseases.",
            "Because fatigue is filtered by the LLM module",
            "Because Cardiologist is never recommended in this setup",
            "Because Dermatologist is the default"
        ],
        "answer": "1"
    },
    {
      "question": "Why does the Random Forest average over 200 trees instead of using a single tree?",
      "options": [
        "To reduce overfitting and stabilize predictions",
        "To decrease computational cost",
        "To avoid using Gini impurity",
        "To generate continuous lab values"
      ],
      "answer": "1"
    },
    {
      "question": "Why might the second-ranked specialist still receive a nonzero probability?",
      "options": [
        "Softmax assigns some weight to every class, even low-score ones",
        "Because the model always shows two specialists",
        "Because Logistic Regression resets biases",
        "Because Random Forest votes again"
      ],
      "answer": "1"
    },
    {
      "question": "How would removing 'red_spots_over_body' from Michael's inputs affect the disease probabilities?",
      "options": [
        "Chicken pox probability would likely decrease",
        "All disease probabilities would sum to more than 100%",
        "Specialist recommendation would stay the same",
        "Red_spots_over_body would become 0.5"
      ],
      "answer": "1"
    },
    {
      "question": "Why do the symptoms 'red_spots_over_body' and 'skin_rash' increase the probability of Chicken pox?",
      "options": [
        "Because they appear in many leaf nodes associated with Chicken pox during training",
        "Because LLM assigns it manually",
        "Because one-hot encoding boosts its weight",
        "Because softmax multiplies it by a constant"
      ],
      "answer": "1"
    },
    {
      "question": "If two patients have identical top-3 disease labels but swapped probabilities (Patient A: [0.50, 0.30, 0.20], Patient B: [0.30, 0.50, 0.20]), how will their specialist recommendations compare?",
      "options": [
        "The system will give the same two specialists in the same order",
        "The system will give the same two specialists, but in reversed order",
        "They may get completely different specialists",
        "Cannot tell without symptom data"
      ],
      "answer": "1"
    },
    {
      "question": "How can a multiclass classifier (e.g., multinomial logistic regression) be used in a specialist recommender system?",
      "options": [
        "By taking the top predicted diseases as input and producing a probability distribution over specialist categories",
        "By clustering doctors into topic models based on symptom text",
        "By generating new symptom features through similarity embeddings",
        "By scoring lab values directly and matching to doctors"
      ],
      "answer": "1"
    },
    {
      "question": "What question would you ask the LLM to check if the LLM model actually used lab values like CRP in its explanation?",
      "options": [
        "Did the model actually use CRP levels as an input feature?",
        "What symptom vector did you use?",
        "Why do probabilities sum to 100%?",
        "How many trees predict Chicken pox?"
      ],
      "answer": "1"
    },
    {
      "question": "Could Michael's red spots be caused by something other than Chicken pox? Which follow-up would probe this?",
      "options": [
        "Could rash be caused by allergy rather than Chicken pox?",
        "What is the solver used in Logistic Regression?",
        "How many trees reached a leaf?",
        "What is the Gini impurity value?"
      ],
      "answer": "1"
    },
    {
      "question": "If Michael actually had Lupus (not in top 3) but Lupus scores only 0.05, what might that suggest about the classifier?",
      "options": [
        "It may be misclassifying Lupus symptoms as Chicken pox",
        "It grouped Lupus under Hepatitis C",
        "It overfits to skin conditions",
        "The specialist model overrides it"
      ],
      "answer": "1"
    },
    {
      "question": "After Michael's scenario, you notice 'Acne' at 10.5%. What could a user ask to understand why Acne scored lower than Hepatitis C?",
      "options": [
        "Which symptom splits favored Hepatitis C over Acne?",
        "How many iterations did the Logistic Regression run?",
        "Why does softmax remove low scores?",
        "What is the patient's CRP level?"
      ],
      "answer": "1"
    },
    {
      "question": "If the softmax probability of the second specialist increased from 5% to 20%, what could have changed?",
      "options": [
        "A third disease with strong weight for that specialist was added",
        "The LLM intervened",
        "Softmax was disabled",
        "One-hot encoding was dropped"
      ],
      "answer": "1"
    }
  ],
  "JaneSmith": [
    {
      "question": "Why does the model give Gastroenterologist such a high confidence score in Jane's case?",
      "options": [
        "Because Gastroenteritis was predicted as the top disease and it's strongly associated with that specialist in training data",
        "Because it is the default recommendation for digestive symptoms",
        "Because vomiting is always mapped to Gastroenterologist",
        "Because softmax boosts the first option"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the model not show just one disease, even when the top prediction is much higher than the rest?",
      "options": [
        "To expose uncertainty and offer users alternative possibilities",
        "To match the number of specialists",
        "To avoid overwhelming the user",
        "To prevent needing LLM assistance"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system use symptoms like nausea and diarrhoea instead of asking for lab values?",
      "options": [
        "Because it was trained only on symptom checklists and not lab data",
        "Because lab values are harder to visualize",
        "Because symptoms don't need softmax normalization",
        "Because nausea is always more accurate"
      ],
      "answer": "1"
    },
    {
      "question": "Why might the model choose Malaria as a lower-ranked prediction despite a weak symptom match?",
      "options": [
        "Because it shares partial overlap (e.g., vomiting) with Jane's input, so it gets a small score from a few trees",
        "Because the specialist model prefers it",
        "Because Malaria is common in the training dataset",
        "Because diarrhoea directly maps to Malaria"
      ],
      "answer": "1"
    },
    {
      "question": "How does the specialist recommendation model (Multinomial Logistic Regression) handle the issue of class imbalance, where some specialists may have fewer training examples than others?",
      "options": [
        "By using the class_weight=\"balanced\" parameter to automatically adjust the weights for each class",
        "By using a weighted loss function that penalizes mistakes on minority classes more heavily",
        "By oversampling the minority classes to balance the training data",
        "By ignoring class imbalance and relying on the model's ability to learn from the majority class"
      ],
      "answer": "1"
    },
    {
      "question": "Why is one-hot encoding used before the Logistic Regression model instead of passing symptoms again?",
      "options": [
        "Because the specialist model only learns from disease names, not raw symptoms",
        "Because symptoms are too noisy for logistic regression",
        "Because it's faster to code that way",
        "Because it simplifies tree traversal"
      ],
      "answer": "1"
    },
    {
      "question": "Why is it helpful for a user to see Chronic cholestasis listed even though it's not the top diagnosis?",
      "options": [
        "Because it reveals alternative interpretations the model considers, which may aid real clinical decision-making",
        "Because it helps balance softmax",
        "Because the specialist depends on seeing three diseases",
        "Because it is needed to trigger the LLM"
      ],
      "answer": "1"
    },
    {
      "question": "Why might a patient's ranking of diseases change if they had reported just two symptoms instead of four?",
      "options": [
        "Because Random Forest decisions rely heavily on symptom combinations and fewer symptoms change the branching logic",
        "Because fewer symptoms are always more accurate",
        "Because the top diseases are selected alphabetically when fewer symptoms are present",
        "Because softmax behaves differently with two inputs"
      ],
      "answer": "1"
    },
    {
      "question": "If two patients have different top-3 labels but same probabilities in the same order, how will their specialist recommendations compare?",
      "options": [
        "Same two specialists in same order",
        "Same two specialists in reversed order",
        "Completely different specialists",
        "Cannot tell without symptom data"
      ],
      "answer": "3"
    },
    {
      "question": "Why is 'diarrhoea' a strong indicator for Gastroenteritis in the Random Forest?",
      "options": [
        "It appears in many decision paths associated with Gastroenteritis",
        "It increases the solver speed",
        "It normalizes fever values",
        "It is ignored by Gini impurity"
      ],
      "answer": "1"
    },
    {
      "question": "How would removing 'vomiting' from Jane's input likely affect the probabilities?",
      "options": [
        "Gastroenteritis probability would decrease",
        "Malaria probability would increase above 50%",
        "Specialist recommendation would switch to Cardiologist",
        "No change"
      ],
      "answer": "1"
    },
    {
      "question": "What would happen if only two disease labels were passed to the specialist classifier?",
      "options": [
        "It would still output probabilities but with less context",
        "It would fail to run",
        "It would duplicate one label",
        "It would output only one specialist"
      ],
      "answer": "1"
    },
    {
      "question": "Explain in simple terms why averaging tree outputs reduces overfitting.",
      "options": [
        "It smooths out individual tree errors by combining many opinions",
        "It always chooses the most common label",
        "It increases model complexity",
        "It avoids using softmax"
      ],
      "answer": "1"
    },
    {
      "question": "Which symptom from Jane's input is most likely ignored by the model?",
      "options": [
        "None - all binary symptom features are processed by the model",
        "Nausea - because it's subjective",
        "Abdominal pain - it is prefiltered",
        "Vomiting - it is not encoded numerically"
      ],
      "answer": "1"
    },
    {
      "question": "Could Jane's diarrhoea be caused by something other than Gastroenteritis? What would you ask?",
      "options": [
        "Could loose stools indicate IBS or food intolerance instead?",
        "What is the LLM's temperature?",
        "Why does the model need 200 trees?",
        "How is softmax computed?"
      ],
      "answer": "1"
    },
    {
      "question": "If the LLM explanation uses lab values like \"...high CRP values indicate...\", which follow-up question to the LLM would reveal that the model did not actually use lab values like CRP?",
      "options": [
        "Did the model actually use CRP levels as an input feature?",
        "What was the patient's temperature?",
        "Why does diarrhoea matter?",
        "How many trees predicted Malaria?"
      ],
      "answer": "1"
    },
    {
      "question": "If a real case of IBS (not in top 3) scored 0.08, what might that suggest?",
      "options": [
        "The model confuses IBS with Gastroenteritis",
        "The specialist classifier overrode it",
        "It was grouped under Chronic cholestasis",
        "It indicates perfect accuracy"
      ],
      "answer": "1"
    },
    {
      "question": "After Jane sees Chronic cholestasis at 22.0%, which question probes why it wasn't at the topmost?",
      "options": [
        "Which symptom splits favored Gastroenteritis over cholestasis?",
        "What LR solver was used?",
        "How many iterations were run?",
        "Why are probabilities percentages?"
      ],
      "answer": "1"
    },
    {
      "question": "If Gastroenteritis and Heartburn share symptoms, what could make the model prefer one over the other?",
      "options": [
        "Symptom frequency and training data leaf distributions",
        "Random weight updates",
        "The order of symptoms in input",
        "LLM preference logic"
      ],
      "answer": "1"
    },
    {
      "question": "A user sees Malaria at 10.5% and wonders if it's significant. What does this score indicate?",
      "options": [
        "Low likelihood but not ruled out entirely",
        "Malaria is most likely",
        "The model made a mistake",
        "The feature vector is incorrect"
      ],
      "answer": "1"
    }
  ],
  "AliceJohnson": [
    {
      "question": "Why does the system suggest Neurological conditions for Alice rather than a Cardiac or skin conditions?",
      "options": [
        "Because symptoms like slurred speech, visual disturbances, and headache are strongly associated with neurological conditions in the model's training data",
        "Because the model assigns all dizziness cases to neurologists",
        "Because neurologists were overrepresented in training",
        "Because cardiologists don't treat slurred speech"
      ],
      "answer": "1"
    },
    {
      "question": "Why might the model assign Hypoglycemia a lower probability even though dizziness is a symptom?",
      "options": [
        "Because dizziness also overlaps with Migraine and Hypertension, and the model's trees weigh these more heavily when paired with visual disturbances",
        "Because the model does not recognize dizziness at all since it is appears as a symptom for many diseases.",
        "Because softmax removes low-ranking diseases",
        "Because the symptom vector was incorrectly processed"
      ],
      "answer": "1"
    },
    {
      "question": "Why does visual disturbance increase the likelihood of Migraine in the Random Forest model?",
      "options": [
        "Because in training data, visual issues commonly co-occurred with Migraine-labeled examples, influencing the tree splits",
        "Because visual symptoms always trigger softmax",
        "Because dizziness reduces visual accuracy",
        "Because Logistic Regression prefers visual cues"
      ],
      "answer": "1"
    },
    {
      "question": "Why doesn't the model simply return a single most likely diagnosis and specialist?",
      "options": [
        "To communicate uncertainty and provide alternative plausible options",
        "Because softmax cannot rank items",
        "Because it cannot sort probabilities",
        "Because LLM decides the number of outputs"
      ],
      "answer": "1"
    },
    {
      "question": "Why might Alice's symptoms be misinterpreted as Hypoglycemia rather than stroke?",
      "options": [
        "Because both share overlapping symptoms like dizziness and fatigue, and the model might have seen more training data for Hypoglycemia",
        "Because the Random Forest ignores dizziness",
        "Because Logistic Regression prioritizes unrelated classes",
        "Because LLM explanations bias toward Hypoglycemia"
      ],
      "answer": "1"
    },
    {
      "question": "Why does softmax assign a small probability to the second specialist instead of showing only one?",
      "options": [
        "Because all specialists receive some nonzero weight",
        "Because two outputs are hardcoded",
        "Because Gini impurity controls softmax",
        "Because this makes the UI easier to read"
      ],
      "answer": "1"
    },
    {
      "question": "Why might removing 'slurred speech' from Alice's input cause Neurologist to no longer be the top specialist?",
      "options": [
        "Because slurred speech is a critical discriminative feature for neurological conditions in the model, and without it, the probability mass redistributes",
        "Because softmax fails without slurred speech",
        "Because slurred speech overrides all diseases",
        "Because the symptom vector becomes incomplete"
      ],
      "answer": "1"
    },
    {
      "question": "Why is it helpful to show confidence scores (e.g. 92% Neurologist, 4% Endocrinologist) instead of only showing labels?",
      "options": [
        "Because it communicates how confident the system is and helps users understand the level of ambiguity in the recommendation",
        "Because the model always generates numbers",
        "Because LLMs require percentages for explanations",
        "Because they are needed to activate decision trees"
      ],
      "answer": "1"
    },
    {
      "question": "If two patients have different top-3 labels but the same probabilities in the same order, how will their specialist recommendations compare?",
      "options": [
        "Same specialists same order",
        "Same specialists reversed order",
        "Completely different specialists",
        "Cannot tell without symptom data"
      ],
      "answer": "3"
    },
      {
      "question": "Suppose you wanted to incorporate additional information about Jane Smith's medical history into the disease prediction model. What would be a suitable approach to integrate this new data?",
      "options": [
        "Add the medical history features as additional inputs to the Random Forest classifier",
        "Use a separate model to predict disease probabilities based on medical history and then combine these predictions with the original model's output",
        "Use transfer learning to adapt a pre-trained model that already incorporates medical history features",
        "Ignore the medical history data, as it may not be relevant to the current symptoms"
      ],
      "answer": "1"
    },
    {
      "question": "Why might the Random Forest associate 'slurred_speech' more with neurological issues than metabolic ones?",
      "options": [
        "It rarely appears outside neurology-related leaf nodes",
        "It normalizes symptom input",
        "It increases solver speed",
        "It is ignored by Gini impurity"
      ],
      "answer": "1"
    },
    {
      "question": "Why might Hypoglycemia still appear with 21% despite being third?",
      "options": [
        "It shares overlapping symptoms with higher-ranked diseases",
        "It was added by the LLM",
        "It always appears for dizziness",
        "It resets the softmax"
      ],
      "answer": "1"
    },
    {
      "question": "What would happen if only one disease label were passed to the specialist model?",
      "options": [
        "It would reduce context and possibly give skewed probabilities",
        "It would crash",
        "The softmax would output binary values",
        "It would average the missing classes"
      ],
      "answer": "1"
    },
    {
      "question": "Explain why averaging many decision trees reduces model variance.",
      "options": [
        "It smooths out individual tree errors by averaging multiple opinions",
        "It always picks the tree with the highest depth",
        "It reduces the number of features",
        "It changes Gini to entropy"
      ],
      "answer": "1"
    },
    {
      "question": "Which symptom change might reduce Alice's top neurologist recommendation?",
      "options": [
        "Removing 'slurred_speech'",
        "Adding 'itching'",
        "Removing 'nausea'",
        "Adding 'weight gain'"
      ],
      "answer": "1"
    },
    {
      "question": "If the LLM explanation uses lab values like \"...high blood pressure indicate...\", which follow-up question to the LLM would reveal if lab values influenced Alice's scores?",
      "options": [
        "Did the model actually use blood pressure readings as input?",
        "What is the Gini impurity threshold?",
        "How many trees predicted Hypoglycemia?",
        "Why does softmax normalize scores?"
      ],
      "answer": "1"
    },
    {
      "question": "Could Alice's headache be caused by dehydration rather than Migraine? What question reveals this?",
      "options": [
        "Could headache indicate dehydration instead of Migraine?",
        "What LR solver was used?",
        "How many symptoms were input?",
        "Why sum probabilities to 100%?"
      ],
      "answer": "1"
    },
    {
      "question": "If the true cause were stroke (not in top 3) scoring 0.08, what does that suggest?",
      "options": [
        "The model may confuse stroke with Migraine",
        "Specialist classifier overruled it",
        "It grouped stroke under Hypertension",
        "It indicates perfect accuracy"
      ],
      "answer": "1"
    },
    {
      "question": "A user sees Hypertension ranked 2nd and wonders if it's less relevant than Migraine. What question helps them understand this?",
      "options": [
        "Which symptoms specifically triggered Hypertension in the random trees used for classification?",
        "What was the model's training accuracy?",
        "How many features are used by softmax?",
        "Was the output normalized?"
      ],
      "answer": "1"
    },
    {
      "question": "Alice is told Neurologist (92%) and Endocrinologist (4%) are top picks. What explains the specialist split?",
      "options": [
        "Neurologist is more directly tied to top disease (Migraine)",
        "Endocrinologist is always second",
        "Softmax was biased",
        "LLM prefers Neurologist"
      ],
      "answer": "1"
    },
    {
      "question": "Although Alice's predicted diseases (Migraine, Hypertension, Hypoglycemia) have similar confidence scores, the system strongly recommends a Neurologist (92.3%). What best explains this?",
      "options": [
        "The Neurologist is recommended because two of the predicted diseases are commonly associated with neurological care, increasing the combined weight for that specialist.",
        "The Neurologist is always preferred when disease probabilities are close together.",
        "The system averages disease and specialist probabilities directly, so similar inputs yield one high output.",
        "The softmax function forces one label to be over 90% whenever three diseases are predicted."
      ],
      "answer": "1"
    }
  ],
  "EmilyDavis": [
  {
    "question": "Why does the model predict Malaria as the top disease for Emily instead of Heart attack or Allergy?",
    "options": [
      "Because symptoms like chills, high fever, sweating, and vomiting closely match Malaria patterns seen during training, making it a strong match across many decision trees",
      "Because chills are exclusive to Malaria",
      "Because softmax amplifies the first disease in the input",
      "Because the LLM ranked Malaria highest"
    ],
    "answer": "1"
  },
  {
    "question": "What is the purpose of using one-hot encoding for the top 3 predicted disease labels as input to the specialist recommendation model?",
    "options": [
      "To ensure that each disease label is treated as a separate, categorical feature",
      "To reduce the dimensionality of the input data and prevent overfitting",
      "To provide a sparse representation of the disease labels, which can improve model performance",
      "To allow the model to capture non-linear relationships between diseases and specialists"
    ],
    "answer": "1"
  },
  {
    "question": "Why does removing 'muscle_pain' from Emily's symptoms likely reduce the probability of Malaria?",
    "options": [
      "Because muscle pain is one of several key features learned from Malaria cases and contributes to Malaria-leaning tree splits",
      "Because it decreases model accuracy",
      "Because LLM cannot interpret muscle-related features",
      "Because Logistic Regression requires it"
    ],
    "answer": "1"
  },
  {
    "question": "Why might Heart attack appear as the second prediction even though many of Emily's symptoms are non-cardiac?",
    "options": [
      "Because some symptoms like sweating and vomiting overlap between Malaria and cardiac conditions, creating ambiguity in tree paths",
      "Because Heart attack is randomly included",
      "Because Logistic Regression overrides Random Forest",
      "Because LLM favors urgent diseases"
    ],
    "answer": "1"
  },
  {
    "question": "Why does the model use probabilities rather than simply showing a single disease and specialist recommendation?",
    "options": [
      "To help users understand model uncertainty and explore alternative diagnoses when symptoms are ambiguous",
      "Because the UI is designed for multiple outputs",
      "Because softmax cannot show just one",
      "Because probabilities activate Gini splits"
    ],
    "answer": "1"
  },
  {
    "question": "Why might Internal Medicine be the top recommended specialist for Emily despite her symptoms matching Malaria?",
    "options": [
      "Because Internal Medicine covers systemic infections like Malaria, and the model learns this association from training examples",
      "Because it always appears first alphabetically",
      "Because the LLM prefers generalists",
      "Because the model can't recommend specialists directly"
    ],
    "answer": "1"
  },
  {
    "question": "Why would a disease like Dengue (not in top-3) be missed by the model even if Emily's symptoms seem consistent with it?",
    "options": [
      "Because Malaria and the other diseases share highly overlapping symptoms and dominate the prediction through stronger tree-path associations in training",
      "Because Dengue was filtered out",
      "Because softmax suppresses tropical diseases",
      "Because Gini ignores blood-based symptoms"
    ],
    "answer": "1"
  },
  {
    "question": "Why is it important to ask if bloodwork or lab values were actually used in the prediction?",
    "options": [
      "Because lab features may falsely appear in explanations even if the model didn't use them",
      "Because lab values always lower accuracy",
      "Because Random Forests require numeric lab inputs",
      "Because softmax discards lab results"
    ],
    "answer": "1"
  },
  {
      "question": "If two patients have similar symptoms but Emily's case scores Malaria highest and another scores Heart Attack highest, what may differ?",
      "options": [
        "Which symptom paths trees split on most strongly",
        "The LLM outputs",
        "The model's bias value",
        "The softmax function used"
      ],
      "answer": "1"
    },
    {
      "question": "Why does 'chills' boost the Malaria probability in the Random Forest?",
      "options": [
        "It appears frequently in malaria-positive leaves during training",
        "It increases the solver speed",
        "It normalizes fever values",
        "It reduces tree depth"
      ],
      "answer": "1"
    },
    {
      "question": "How would removing 'muscle_pain' affect Emily's disease probabilities?",
      "options": [
        "Malaria probability might decrease slightly",
        "Heart attack would dominate",
        "Allergy would become top disease",
        "No change"
      ],
      "answer": "1"
    },
    {
      "question": "Explain why averaging many trees reduces prediction variance.",
      "options": [
        "Combining multiple tree opinions smooths out individual errors",
        "It always picks the deepest tree",
        "It removes low-probability diseases",
        "It changes symptoms to lab values"
      ],
      "answer": "1"
    },
    {
      "question": "Why might 'Allergy' still appear at 4.0% despite low score?",
      "options": [
        "Softmax gives every class some weight",
        "It was manually inserted",
        "It is required by the UI",
        "It resets Gini impurity"
      ],
      "answer": "1"
    },
    {
      "question": "What would happen if Emily had entered fewer than three symptoms?",
      "options": [
        "The model may produce low-confidence predictions",
        "It would crash",
        "It would show no specialists",
        "It would generate a different one-hot encoding"
      ],
      "answer": "1"
    },
    {
      "question": "If the LLM explanation uses lab values like \"...high blood pressure indicate...\", which follow-up question to the LLM would reveal if lab values influenced Emily's scores?",
      "options": [
        "Did the model actually use any blood work inputs?",
        "How many trees predicted Heart attack?",
        "What is the Logistic Regression solver?",
        "Why do probabilities sum to 100%?"
      ],
      "answer": "1"
    },
    {
      "question": "Could Emily's high fever indicate influenza rather than Malaria? Which follow-up probes this?",
      "options": [
        "Could fever without chills point to influenza instead of malaria?",
        "Why is softmax used?",
        "What is Gini impurity?",
        "How many symptoms were input?"
      ],
      "answer": "1"
    },
    {
      "question": "If Emily actually had dengue (not in top 3) scoring 0.05, what might that suggest?",
      "options": [
        "The model may confuse dengue with Malaria",
        "Specialist classifier overrode it",
        "It grouped dengue under Heart attack",
        "It indicates perfect accuracy"
      ],
      "answer": "1"
    },
    {
      "question": "Emily notices Allergy ranked 3rd and wonders why. What question would clarify that?",
      "options": [
        "Which specific symptoms contributed to Allergy scoring 4%?",
        "Is 4% below softmax threshold?",
        "How many iterations were run?",
        "What is the default label?"
      ],
      "answer": "1"
    },
    {
      "question": "The Internal Medicine specialist received 72% probability. What does that reflect?",
      "options": [
        "Strong connection between predicted diseases and this specialty",
        "The model's default fallback",
        "That Heart Attack was highly likely",
        "The model ignored symptom severity"
      ],
      "answer": "1"
    },
    {
      "question": "Emily's specialist output changed when 'headache' is added. What does this reveal about the model?",
      "options": [
        "It is sensitive to specific input changes and re-aggregates predictions accordingly",
        "It always lowers older scores when new symptoms are added",
        "It prefers neurologists for any head-related symptom",
        "The softmax ignores all binary features"
      ],
      "answer": "1"
    }
  ]
}
