{
  "MichaelBrown": [
    {
      "question": "Why is 'red spots over body' a strong indicator for diseases like Chicken Pox and Acne in Michael's case?",
      "options": [
          "Because the symptom frequently co-occurs with diseases like Chicken Pox and Acne in the training data, leading the model to link them",
          "Because the system directly assigns any skin disease at random whenever it detects this symptom",
          "Because 'red spots over body' is a unique indicator for Dermatologists, which the system always associates",
          "Because the model was trained only on skin diseases, making it less capable of predicting other conditions"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system say Chicken pox is more likely than Acne or Hepatitis C for Michael?",
      "options": [
        "Because symptoms like rash and red spots match Chicken pox cases in the training data",
        "Because the system saw Chicken pox earlier than the other diseases during training",
        "Because Acne was excluded during preprocessing",
        "Because Chicken pox appears first in a large number of training instances"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system list Acne as the second most likely disease even though its probability is much lower than Chicken pox?",
      "options": [
          "Because it's still the second most likely diagnosis based on Michael's symptoms",
          "Because the output ranking reflects relative order, even if the scores are very different",
          "Because the system includes common conditions to make sure they are considered",
          "Because low-probability diseases occasionally appear if no stronger matches exist"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system still show some chance (a low probability) for Hepatitis C in Michael's results?",
      "options": [
          "Because symptoms like fatigue and lethargy partially match cases labeled as Hepatitis C in training",
          "Because the system assigns small probabilities to diseases with marginal symptom overlap",
          "Because liver-related diseases tend to show up when symptoms are vague",
          "Because the system always spreads some chance across diseases (softmax distributes probability), even for weak matches."
      ],
      "answer": "1"
    },
    {
      "question": "In the system's input, how is the symptom 'fatigue' represented?",
      "options": [
        "1 if fatigue is present, 0 if absent",
        "The overall importance score of fatigue across trees",
        "The probability of fatigue predicted by softmax",
        "A continuous measurement from clinical lab results"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system not list a Cardiologistas one of the recommended specialists even though Michael reported fatigue?",
      "options": [
          "Because the system looks at all symptoms, and fatigue overlaps with many non-cardiac conditions",
          "Because fatigue may be ignored by the LLM explanation module",
          "Because Cardiologists are excluded when 'fatigue' is mild",
          "Because skin symptoms dominate the system results, and 'fatigue' is not relevant"
      ],
      "answer": "1"
    },
    {
      "question": "Why do the symptoms 'red_spots_over_body' and 'skin_rash' increase the probability of Chicken pox in the system's result?",
      "options": [
        "Because they appear in  decision trees that vote for Chicken pox",
        "Because the system applies an extra weight to skin-related symptoms",
        "Because skin indicators are scaled higher than other inputs",
        "Because these symptoms tend to bias predictions toward all skin diseases"
      ],
      "answer": "1"
    },




    {
      "question": "If the LLM explanation claims \"elevated CRP levels indicate a stronger diagnosis,\" what follow-up question should you ask to check if the system actually used CRP in its analysis?",
      "options": [
        "Did the disease model include C-reactive protein (CRP) measurements among its input features?",
        "How many decision trees in the forest calculated CRP thresholds for splitting?",
        "Can you show how the symptom list was constructed without lab values?",
        "What step adjusts the predictions based on lab results?"
      ],
      "answer": "1"
    },
    {
      "question": "What is the primary reason for using a Random Forest classifier as the disease prediction model in this system?",
      "options": [
        "To take advantage of the ensemble method's ability to reduce errors and make more reliable predictions",
        "To handle symptoms in chronological order and prioritize the most recently reported ones",
        "To reduce computation time by limiting the number of decisions compared to other models",
        "To ensure that only a single symptom determines the final disease prediction for easier interpretation"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the Random Forest combine the results of 200 trees instead of just one?",
      "options": [
          "Because it reduces overfitting and produces more stable results",
          "Because it is faster than using fewer trees by parallelizing operations",
          "Because using 100s of trees avoids using Gini impurity, making the overall process simpler",
          "Because a large number of trees generate continuous symptom scores"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system still show a small probability for the second-ranked specialist?",
      "options": [
        "Because the model assigns some chance to every specialist",
        "Because the interface is designed to always display two specialists",
        "Because Logistic Regression resets probabilities below a threshold",
        "Because Random Forest re-votes for specialists after disease prediction"
      ],
      "answer": "1"
    },
    {
      "question": "How can a multiclass classifier (e.g., multinomial logistic regression) be used to recommend a specialist?",
      "options": [
        "By taking the top disease predictions and outputting a probability for specialists",
        "By clustering symptom and matching nearest specialists",
        "By mapping symptom directly to specialist without intermediate disease labels",
        "By using continuous lab measurements to adjust specialist scores during training"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system use a one-hot representation of the top 3 diseases (instead of using the symptoms directly) to recommend a specialist?",
      "options": [
        "Because it ensures that each disease is clearly represented and mapped properly to specialists",
        "Because it reduces the number of symptoms considered and ignores less important ones completely",
        "Because it allows the system to use lab test results alongside symptoms for providng the recommendations",
        "Because it automatically ranks symptoms by severity before choosing a specialist"
      ],
      "answer": "1"
    },




    {
      "question": "Could Michael's red spots be caused by something other than Chicken pox? Which follow-up would would help you explore this possibility?",
      "options": [
        "Could the rash be due to an allergic reaction rather than Chicken pox?",
        "Does the model give equal weight to all skin symptoms, causing rash to trigger Chicken pox predictions?",
        "Could a mistake in the disease labels be inflating the Chicken pox score?",
        "Is the symptom co-occurrence matrix biased toward Chicken pox for any rash-like inputs?"
      ],
      "answer": "1"
    },
    {
      "question": "After Michael's scenario, you notice 'Acne' at 10.5%. What question could help you understand why Acne scored lower than Hepatitis C?",
      "options": [
        "Which decision tree paths favored Hepatitis C over Acne?",
        "Could removing a symptom like fatigue increase Acne's score instead?",
        "Did the system prioritize more severe diseases when symptoms overlapped?",
        "Which lab test values influenced the Acne prediction score?"
      ],
      "answer": "1"
    },
    {
      "question": "Why would removing 'skin_rash' from Michael's symptoms affect the chance that the system recommends a Dermatologist?",
      "options": [
          "Because removing it weakens the system's confidence in skin diseases",
          "Because it causes the softmax to ignore skin-related symptoms",
          "Because removing a key symptom causes significant shifts in symptom distributions that the model cannot properly adjust for",
          "Because missing symptoms can affect decision tree splits that lead to specialist predictions"
      ],
      "answer": "1"
    },
    {
      "question": "Why might adding 'itching' as a symptom make Chicken Pox even more likely?",
      "options": [
          "Because itching often appeared with Chicken pox in training data",
          "Because adding symptoms will always increase all probability scores",
          "Because itching has built-in probability weights",
          "Because adding itching reduces scores of other specialists"
      ],
      "answer": "1"
    },
    {
      "question": "If Michael's actual condition was Lupus but the system only gave it a 5% chance, what does that suggest about the system?",
      "options": [
        "It may be misclassifying Lupus symptoms as resembling Chicken pox",
        "It implies Lupus is grouped under Hepatitis C by the model",
        "It indicates the system focuses too much on common diseases",
        "It shows the specialist module overrides disease scores"
      ],
      "answer": "1"
    },
    {
      "question": "If two patients have identical top-3 disease labels but swapped probabilities (Patient A: [0.50, 0.30, 0.20], Patient B: [0.30, 0.50, 0.20]), how will their specialist recommendations compare?",
      "options": [
        "The system will give the same two specialists in the same order",
        "The system will give the same two specialists, but in reversed order",
        "They may get completely different specialists",
        "Cannot tell without symptom data"
      ],
      "answer": "1"
    },
    {
      "question": "How would removing 'red_spots_over_body' from Michael's symptoms change the disease predictions?",
      "options": [
        "Chicken pox probability would likely decrease due to removal of a key skin-related indicator",
        "All predicted disease probabilities would incorrectly redistribute and add up to more than 100%",
        "The probability for Dermatologist recommendation would remain largely unchanged despite the missing symptom",
        "The system would set a random value for the missing symptom"
      ],
      "answer": "1"
    }
  ],
  "JaneSmith": [
    {
      "question": "Why does the system think 'diarrhoea' strongly suggests the need to see a Gastroenteritis?",
      "options": [
        "Because it often appeared together with Gastroenteritis cases in the examples the model learned from, and it strongly influences its decisions",
        "Because it boosts the disease score by amplifying the probability through the final calculation",
        "Because the system is designed to recommend digestive diseases whenever diarrhoea is present",
        "Because diarrhoea masks all other symptoms in the model's input before prediction"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the model strongly recommend seeing a Gastroenterologist for Jane?",
      "options": [
        "Because Gastroenteritis was predicted as the top diseasee, and that disease is closely linked to a Gastroenterologist",
        "Because the model always recommends a Gastroenterologist when stomach problems are reported",
        "Because vomiting alone always triggers the Gastroenterologist recommendation",
        "Because the model gives the first specialist a boost without checking others"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the model still include Malaria even though Jane's symptoms don't match it well?",
      "options": [
        "Because it shares some symptoms (like vomiting) with Jane's input, so a few of the decision trees gave it a small score",
        "Because the specialist prediction may influence disease probabilities during postprocessing",
        "Because Malaria appeared frequently in similar clinical cases the model learned from",
        "Because symptoms like diarrhoea can sometimes be loosely associated with Malaria in the data"
      ],
      "answer": "1"
    },
    {
      "question": "A user sees Malaria at 10.5% and wonders if it's significant. What does this score indicate?",
      "options": [
        "It suggests a low likelihood but not one that can be entirely ruled out",
        "It indicates that Malaria is the most probable diagnosis based on the symptoms",
        "It reflects that the model likely misinterpreted the symptom",
        "It means the symptom inputs were not properly handled"
      ],
      "answer": "1"
    },
    {
      "question": "Which symptom from Jane's input is most likely ignored by the model?",
      "options": [
        "None - all binary symptom features are processed by the model",
        "Nausea - because it's subjective",
        "Abdominal pain - it is prefiltered",
        "Vomiting - it is not encoded properly"
      ],
      "answer": "1"
    },
    {
      "question": "After Jane sees Chronic cholestasis at 22.0%, which question could explain why it wasn't the disease?",
      "options": [
        "Which symptom led the system to choose Gastroenteritis over Chronic cholestasis?",
        "Why is Chronic cholestasis capped at a certain score?",
        "Does the model dislike liver diseases like cholestasis by default?",
        "Was cholestasis probability reduced due to overlap with unrelated symptoms?"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the model still list Malaria even though it's very unlikely?",
      "options": [
        "Because the model gives a small chance to all diseases, even less likely ones",
        "Because it may be manually included as part of a baseline condition set",
        "Because the user interface adds random diseases to fill the list of three diseases",
        "Because the model resets some scores during prediction"
      ],
      "answer": "1"
    },




    {
      "question": "If the LLM says \"high blood sugar values suggest systemic inflammation,\" which question would check if the model actually used blood sugar data?",
      "options": [
        "Were blood sugar measurements actually part of the training features?",
        "How accurate is the model when the patient states that blood sugar is high?",
        "Why does vomiting link to blood sugar in this explanation?",
        "How many trees in the random forest model split on blood sugar values?"
      ],
      "answer": "1"
    },
    {
      "question": "Explain in simple terms why averaging tree outputs reduces overfitting",
      "options": [
        "Because it smooths out individual tree errors by combining many independent decisions",
        "Because it always selects the most common answer from one tree",
        "Because it increases the number of splits per tree to make them more accurate",
        "Because it avoids softmax by distributing votes across all possible classes"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the specialist model use the predicted diseases instead of symptoms?",
      "options": [
        "Because the specialist model is trained only to use diseases, not symptoms",
        "Because symptom introduce noise that harms the specialist model's accuracy",
        "Because it is easier to build the system this way",
        "Because tree-based splitting cannot process symptom as inputs"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the model show more than one disease, even when the top prediction score is much higher than the rest?",
      "options": [
        "To expose uncertainty and offer users alternative plausible diagnoses alongside the top choice",
        "To maintain alignment with the specialist recommendation module's expected three disease as input",
        "To comply with interface guidelines that display multiple options for informed decision-making",
        "To ensure the system keeps record of all outputs for each case"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system use symptoms like nausea and diarrhoea instead of asking for lab tests?",
      "options": [
        "Because it was trained only on symptom checklists and not lab data",
        "Because lab values are harder to visualize",
        "Because symptoms don't need softmax normalization",
        "Because reporting symptoms lead to more accurate results"
      ],
      "answer": "1"
    },
    {
      "question": "Why is it helpful for a user to see Chronic cholestasis and Malaria listed even though they are not the top diagnosis?",
      "options": [
        "Because it helps users consider other possibilities too",
        "Because the system requires three diseases to maintain consistent layout",
        "Because seeing rarer conditions improves the calibration",
        "Because listing extra diagnoses triggers deeper LLM explanations"
      ],
      "answer": "1"
    },



    {
      "question": "Why might a patient's ranking of diseases change if they had reported just two symptoms instead of four?",
      "options": [
        "Because decision tree splits depend on specific symptom combinations, so fewer inputs alter the branching logic",
        "Because reducing the number of symptoms automatically increases the prediction confidence",
        "Because with fewer inputs the model sorts diseases alphabetically",
        "Because softmax normalization treats input with two symptoms differently than four symptom"
      ],
      "answer": "1"
    },
    {
      "question": "Could Jane's diarrhoea be caused by something other than Gastroenteritis? What would you ask to clarify this?",
      "options": [
        "Could loose stools indicate IBS or a food intolerance rather than Gastroenteritis?",
        "Could the model's learning rate affect diarrhoea predictions?",
        "Could tree depth bias the model toward stomach-related conditions?",
        "Could softmax hide other stomach-related diagnoses?"
      ],
      "answer": "1"
    },
    {
      "question": "What would happen to the system's prediction if 'vomiting' is not reported to the system in Jane's case?",
      "options": [
        "The chance of Gastroenteritis being recommended would drop",
        "The model would become more certain about the specialist recommendation",
        "Specialist recommendation would switch to Cardiologist",
        "There would be no noticeable effect on the predictions"
      ],
      "answer": "1"
    },
    {
      "question": "If Gastroenteritis and Heartburn share symptoms, what could make the model prefer one over the other?",
      "options": [
        "Because the model relies on patterns it learned from past examples",
        "Because of random symptom changes during prediction",
        "Because of the order symptoms were entered",
        "Because the language model prefers certain words"
      ],
      "answer": "1"
    },
    {
      "question": "If a confirmed case of IBS scored only 8%, what might that indicate about the model's behavior?",
      "options": [
        "It suggests the model confuses IBS symptoms with Gastroenteritis",
        "It implies IBS is captured under Chronic cholestasis predictions",
        "It indicates the specialist classifier lowered IBS scores",
        "It reflects perfect generalization for stomach-related conditions"
      ],
      "answer": "1"
    },
    {
      "question": "If two patients have different top-3 labels but same probabilities in the same order, how will their specialist recommendations compare?",
      "options": [
        "Same two specialists in same order",
        "Same two specialists in reversed order",
        "Completely different specialists",
        "Cannot tell without symptom data"
      ],
      "answer": "3"
    },
    {
      "question": "What would happen if only two disease labels are sent to the specialist classifier?",
      "options": [
        "It would still predict specialists but with less information",
        "The specialist classifier would produce an error because the input size is wrong",
        "It duplicates a disease to fill the list of input diseases to the classifier",
        "It would return only a single specialist recommendation due to incomplete label inputs"
      ],
      "answer": "1"
    }
  ],
  "AliceJohnson": [
    {
      "question": "Why does the system connect 'slurred speech' more to neurological problems than to metabolic problems?",
      "options": [
        "Because the system learned from past examples that slurred speech is more common in neurological diseases",
        "Because slurred speech is automatically given more weight in the calculations",
        "Because the system boosts scores for brain-related symptoms using a special function whenever there are neurological symptoms",
        "Because slurred speech is hardcoded to always lead to a Neurologist"
      ],
      "answer": "1"
    },
    {
      "question": "Why does reporting vision problems make the system more likely to predict Migraine?",
      "options": [
        "Because vision problems often appeared with Migraine in the examples the system learned from",
        "Because vision problems trigger an extra scoring step in the system",
        "Because dizziness and vision problems are always grouped together in the model",
        "Because the system gives extra points to any brain-related symptoms"
      ],
      "answer": "1"
    },
    {
      "question": "If Hypertension is ranked lower than Migraine, what question would you ask to understand why it is so?",
      "options": [
        "Which symptoms specifically triggered Hypertension in the random trees used for classification?",
        "How accurate was the system for Hypertension during its training?",
        "How many symptoms indirectly contributed to Hypertension's probability score?",
        "Did the system adjust Hypertension's score after its first calculation?"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system suggest Neurological diseases for Alice rather than a Cardiac or skin diseases?",
      "options": [
        "Because her symptoms are strongly associated with neurological conditions in the examples the system learned from",
        "Because the system prefers neurological diseases when multiple vague symptoms are present assuming it to be a complex situation",
        "Because Neurological predictions are more likely when headache is included",
        "Because symptoms like slurred speech does not help identify heart or skin problems"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system give Hypoglycemia a lower score even though dizziness is one of Alice's symptoms?",
      "options": [
        "Because dizziness is also common in Migraine and Hypertension, and the system leans toward those when combined with vision problems",
        "Because the system reduces the weight of common symptoms like dizziness to reduce confusion in decision tree splits",
        "Because the system spreads some score to all diseases even if they're not likely, rather than excluding low-scoring conditions entirely",
        "Because the symptom preprocessing step may adjust symptoms unevenly, reducing the relative influence of dizziness on final scores"
      ],
      "answer": "1"
    },
    {
      "question": "Why might Alice's symptoms be misinterpreted by the system as Hypoglycemia rather than stroke?",
      "options": [
        "Because both conditions share those symptoms and the system saw more examples of Hypoglycemia during training",
        "Because the disease prediction component of the system ignored ignores brain-related symptoms like dizziness",
        "Because the system is designed to prioritize less severe conditions to avoid causing unnecessary alarm",
        "Because the LLM explanation tool pushes the result toward metabolic causes and thus changes disease predictions"
      ],
      "answer": "1"
    },
    {
      "question": "The system picks Neurologist (92%) and Endocrinologist (4%) as the top specialist picks for Alice's case. What explains the specialist split?",
      "options": [
        "Because Migraine has a high score, and that pushes the Neurologist score up in the second part of the system",
        "Because the system defaults to Endocrinology as a secondary specialist when scores for first specialist recommendation is more than 90%",
        "Because the system's balancing mechanism favors more common specialties",
        "Because the explanation tool redistributes final scores to simplify the output for users"
      ],
      "answer": "1"
    },




    {
      "question": "If the LLM explanation mentions \"elevated blood pressure indicates neurological risk,\" what would you ask to verify if the system actually used blood pressure as an input?",
      "options": [
        "Did the model actually use blood pressure measurements when making its prediction?",
        "At what point did the system split decisions based on blood pressure?",
        "How many trees voted for Hypoglycemia based on blood pressure?",
        "How does the system decide the importance of blood pressure when choosing which specialist to recommend?"
      ],
      "answer": "1"
    },
    {
      "question": "Why does combining the votes of many trees make the system's predictions more stable?",
      "options": [
        "Because it balances out random or noisy decisions by averaging many different trees",
        "Because it picks the deepest tree and lets it guide the others",
        "Because it ignores low-importance symptoms in the trees during splits",
        "Because it applies a smoothing step after the trees vote to make the predictions more consistent"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system still show a small percentage for the second specialist instead of just showing the top one?",
      "options": [
        "Because the system spreads some score across all specialists so users can see less likely options too",
        "Because the interface is set up to always show two specialists and therefore the system must provide two recommendations",
        "Because the tree calculations are designed in a way that force two scores to appear",
        "Because showing more recommendation looks clearer in the final results"
      ],
      "answer": "1"
    },
    {
      "question": "Although Alice's predicted diseases (Migraine, Hypertension, Hypoglycemia) have similar scores, the system strongly recommends a Neurologist (92.3%). What best explains this?",
      "options": [
        "Because multiple predicted diseases share strong associations with neurological care, boosting their combined specialist score",
        "Because the system defaults to Neurologist as the top specialist when disease probabilities are close together",
        "Because the system directly averages disease and specialist scores, so one specialist comes out highest",
        "Because the system is designed to always make one recommendation with high score (exceeding 90%)"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system show more than one possible disease and specialist instead of just the top one?",
      "options": [
        "Because it allows to communicate uncertainty and provide alternative plausible options",
        "Because the system is built to show a full list of possibilities",
        "Because the system's design requires more than one output for later steps",
        "Because specialist scores rely on comparative scores across multiple diseases"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the system show percentages (e.g. Neurologist - 92% , Endocrinologist - 4%) next to the specialist names?",
      "options": [
        "To show how sure the system is about each recommendation and to highlight where there's uncertainty",
        "Because the system's design always outputs numbers and names together",
        "Because LLM-derived explanations require percentage scored and names to generate narratives",
        "Because the percentages reflect how often each specialist was selected in similar past cases"
      ],
      "answer": "1"
    },




    {
      "question": "Why could removing 'slurred speech' from Alice's symptoms make the system stop recommending a Neurologist?",
      "options": [
        "Because slurred speech is a is a key symptom for neurological conditions, and without it the score for a Neurologist recommendation drops",
        "Because the system depends heavily on key Neurological symptoms like slurred speech, so removing it lowers confidence in all predictions",
        "Because removing symptoms confuses the system, and it cannot figure out the correct prediction",
        "Because missing symptoms leave the input incomplete and lower confidence for all outcomes"
      ],
      "answer": "1"
    },
    {
      "question": "What question could you ask to check if Alice's headache is from dehydration instead of Migraine?",
      "options": [
        "Could headache indicate dehydration instead of Migraine?",
        "Which method was used to decide on Migraine?",
        "How many symptoms contributed to the score for dehydration?",
        "Do the scores for dehydration and Migraine add up to 100%?"
      ],
      "answer": "1"
    },
    {
      "question": "If stroke is the real problem but the system only gives it 8%, what does that tell you?",
      "options": [
        "The system may confuse stroke symptoms with those of Migraine",
        "The system combines stroke into the Hypertension category",
        "It indicates the specialist model within the system lowers the stroke score",
        "The system treats stroke as a rare condition"
      ],
      "answer": "1"
    },
    {
      "question": "If two patients have different top-3 labels but the same probabilities in the same order, how will their specialist recommendations compare?",
      "options": [
        "They will get the same specialists in the same order",
        "They will get the same specialists but in reversed order",
        "They will get completely different specialists",
        "Cannot tell without symptom data"
      ],
      "answer": "3"
    },
    {
      "question": "What happens if the system only uses one predicted disease to recommend specialists?",
      "options": [
        "The predictions become less balanced because the system has less information",
        "The system fails to run because it expects more information",
        "The scores all go to one specialist because there are no alternatives",
        "The system fills in missing diseases with zeros, which distorts the results"
      ],
      "answer": "1"
    },
    {
      "question": "If Alice only reported dizziness and vision problems, and not slurred speech or headache, how would the predictions likely change?",
      "options": [
        "Neurological conditions would still be likely because those two symptoms are linked to them",
        "The system would switch to recommending a Cardiologist because dizziness strongly suggests heart issues",
        "The system would stop working because at least three symptoms are required",
        "The system would produce random results because it lacks enough information"
      ],
      "answer": "1"
    },
    {
      "question": "If Alice had reported nausea instead of slurred speech, how might the system's recommended specialists change?",
      "options": [
        "The system's confidence in a Neurologist might go down, and the chance of recommending an Endocrinologist could go up",
        "The system would ignore nausea because it wasn't part of the training examples",
        "The system would automatically recommend a Gastroenterologist because nausea always leads to that particular specialist in the system",
        "The specialist recommendation would stay the same because only the top ppredicted diseases matter"
      ],
      "answer": "1"
    }
  ],
  "EmilyDavis": [
    {
      "question": "Why does the model predict Malaria as the top disease for Emily instead of Heart attack or Allergy?",
      "options": [
        "Because multiple symptoms like chills, fever, vomiting, and muscle pain match Malaria patterns learned during training",
        "Because chills are a unique symptom of Malaria and are rarely associated with any other diseases in the dataset",
        "Because softmax tends to emphasize the first disease in the prediction list, which is Malaria in this case",
        "Because the LLM highlights infectious diseases more prominently, influencing model's prediction"
      ],
      "answer": "1"
    },
    {
      "question": "Why might Heart attack appear as the second prediction even though many of Emily's symptoms are non-cardiac?",
      "options": [
        "Because some symptoms like sweating and vomiting overlap between Malaria and cardiac conditions, creating ambiguity in tree paths",
        "Because certain non-cardiac symptoms still contribute partial support to cardiac classes during tree aggregation",
        "Because Heart attack can receive moderate probability if overlapping symptoms trigger multiple branches in the forest",
        "Because ambiguous symptoms can activate decision paths linked to both infectious and cardiac categories"
      ],
      "answer": "1"
    },
    {
      "question": "Emily notices Allergy ranked 3rd and wonders why. What question would clarify that?",
      "options": [
        "Which specific symptoms contributed to Allergy scoring 4%?",
        "Does the model prioritize Allergy when Malaria and Heart attack are uncertain?",
        "Is Allergy added as a fallback when non-skin symptoms are weak?",
        "Was Allergy included because it shares minor symptom overlap with all of Emily's symptoms?"
      ],
      "answer": "1"
    },
    {
      "question": "The Internal Medicine specialist received 72% probability. What does that reflect?",
      "options": [
        "A strong learned association between predicted diseases and this specialty",
        "It is the model's default fallback when specialist probabilities are ambiguous",
        "That Heart Attack probability alone determined the specialist recommendation",
        "That symptom severity was ignored in computing specialist scores"
      ],
      "answer": "1"
    },
    {
      "question": "Why might Internal Medicine be the top recommended specialist for Emily despite her symptoms matching Malaria?",
      "options": [
        "Because Internal Medicine covers systemic infections like Malaria and the model learned this association from data",
        "Because the system orders specialists as per the order in training data and Internal Medicine appears first in the list",
        "Because the LLM explanation component introduces a bias toward recommending generalist specialties by default",
        "Because the specialist model fallback logic prioritizes general medicine in ambiguous cases"
      ],
      "answer": "1"
    },
    {
      "question": "Why would a disease like Dengue (not in top-3) be missed by the model even if Emily's symptoms seem consistent with it?",
      "options": [
      "Because Malaria and other top diseases share stronger symptom-path associations in the training trees, resulting in higher scores",
      "Because Dengue cases were intentionally underrepresented in the training dataset, reducing its learned likelihood",
      "Because the softmax normalization step de-emphasizes lower-frequency tropical illnesses in final probability outputs",
      "Because blood chemistry features like platelet count dominate over symptom-only patterns during tree splits"
      ],
      "answer": "1"
    },
    {
      "question": "Why is it important to ask if bloodwork or lab values were actually used in the prediction?",
      "options": [
        "Because explanation layers may reference lab features even if the model was trained only on symptoms",
        "Because including lab values can introduce multicollinearity that skews tree splits",
        "Because numeric lab inputs require additional preprocessing not covered in the standard pipeline",
        "Because probability normalization handles lab-derived and symptom features differently"
      ],
      "answer": "1"
    },


    {
      "question": "If the LLM explanation claims \"blood work results influence the score,\" which question would clarify whether any lab-based blood tests were included in Emily's prediction model?",
      "options": [
        "Were any laboratory blood test results included among the model's input features?",
        "How many trees in the Random Forest referenced blood work in their splitting logic?",
        "What Logistic Regression solver handles lab-derived variables?",
        "Why do the output probabilities sum to 100% when using blood work?"
      ],
      "answer": "1"
    },
    {
      "question": "Explain why averaging many trees reduces prediction variance",
      "options": [
        "Combining multiple tree predictions helps cancel out inconsistent errors across individual trees",
        "It picks the tree with the highest accuracy and favors its prediction",
        "Averaging over a large number of trees filters out rare diseases that occur with low probability",
        "It converts binary symptom inputs into lab-based measurements for higher precision"
      ],
      "answer": "1"
    },
    {
      "question": "What is the purpose of using one-hot encoding for the top 3 predicted disease labels as input to the specialist recommendation model?",
      "options": [
        "To ensure each predicted disease is treated as a distinct categorical feature",
        "To reduce the dimensionality of the input data and prevent overfitting",
        "To provide a sparse representation of the disease labels, which can improve model performance",
        "To allow the model to capture non-linear relationships between diseases and specialists"
      ],
      "answer": "1"
    },
    {
      "question": "Why does the model use probabilities rather than simply showing a single disease and specialist recommendation?",
      "options": [
        "To convey uncertainty and allow exploration of alternative diagnoses when symptom overlap is high",
        "To provide probability inputs required by downstream modules for alerting and clinical workflows",
        "To comply with interface requirements for displaying complete prediction distributions transparently",
        "To enable risk stratification and threshold-based prioritization in subsequent decision support tools"
      ],
      "answer": "1"
    },
    {
      "question": "How does the specialist recommendation model (Multinomial Logistic Regression) handle the issue of class imbalance, where some specialists may have fewer training examples than others?",
      "options": [
        "By using class_weight=\"balanced\" to adjust each specialist's weight inversely to its training frequency",
        "By employing a weighted loss that penalizes errors on underrepresented specialist classes more heavily",
        "By oversampling cases for specialists with fewer examples to balance the training set",
        "By ignoring imbalance and relying on default parameter settings for specialist learning"
      ],
      "answer": "1"
    },
    {
      "question": "Suppose you wanted to incorporate additional information about Emily's medical history into the disease prediction model. What would be a suitable approach to integrate this new data?",
      "options": [
        "Include historical health features directly in the Random Forest's input feature set alongside symptom indicators",
        "Train a separate model on medical history data and ensemble its probability outputs with the primary classifier's predictions",
        "Apply transfer learning to fine-tune a pre-trained model that already integrates patient history information",
        "Omit medical history from the inputs to avoid potential noise and focus only on current symptom data"
      ],
      "answer": "1"
    },




    {
      "question": "Could Emily's high fever indicate influenza rather than Malaria? Which follow-up probes this?",
      "options": [
        "Could the model be using fever severity thresholds to differentiate influenza from Malaria?",
        "Could softmax weighting favor certain diseases when input values exceed a threshold?",
        "Could the Random Forest's Gini splits ignore temperature readings if they're out of range?",
        "Could missing chills data cause the model to default to influenza predictions?"
      ],
      "answer": "1"
    },
    {
      "question": "Emily's specialist recommendation changed when 'headache' was added. What does this reveal about the model?",
      "options": [
        "That predictions are sensitive to individual symptom inputs and update the specialist probabilities dynamically",
        "That the model deprioritizes previous symptoms automatically when new ones arrive",
        "That neurologist recommendations override other specialties whenever head-related symptoms are present",
        "That softmax reassigns all probability mass to newly added features exclusively"
      ],
      "answer": "1"
    },
    {
      "question": "Why does removing 'muscle_pain' from Emily's symptoms likely reduce the probability of Malaria?",
      "options": [
        "Because muscle pain is one of several key features learned from Malaria cases and contributes to Malaria-leaning tree splits",
        "Because the model's overall prediction confidence decreases without muscle pain in the symptom set",
        "Because without muscle pain, the model's feature interpretation becomes less certain for infectious diseases",
        "Because the disease classifier requires muscle-related symptoms to generate accurate predictions"
      ],
      "answer": "1"
    },
    {
      "question": "What would happen if Emily had entered fewer than three symptoms?",
      "options": [
        "The model may produce low-confidence predictions",
        "The system might fail due to insufficient symptom input",
        "Specialist recommendations may be unavailable without enough symptoms",
        "The one-hot encoding vector would be shorter and impact prediction"
      ],
      "answer": "1"
    },
    {
      "question": "If Emily had reported chills but no fever, what might the model predict differently?",
      "options": [
        "It might reduce Malaria's probability while increasing likelihood of other infections",
        "It would completely ignore chills because 'chills' is irrelevant without 'fever'",
        "It would automatically recommend Internal Medicince as specialist since there is no fever but there is sweating",
        "The probabilities would remain identical because symptoms are binary and both fever and chills contibute '1' in the encoding."
      ],
      "answer": "1"
    },
    {
      "question": "If Emily actually had dengue but it only scored 5%, what might that suggest about the classifier?",
      "options": [
        "It may confuse dengue symptoms with those of Malaria",
        "It implies dengue is treated like a cardiovascular condition",
        "It indicates the model underrepresents mosquito-borne diseases",
        "It shows the system defaults to more common infections"
      ],
      "answer": "1"
    }, 
    {
      "question": "If two patients have similar symptoms but Emily's case scores Malaria highest and another scores Heart Attack highest, what should you ask to understand the difference?",
      "options": [
        "Which symptom paths the trees split on most strongly for each patient?",
        "How the LLM decides between divergent disease outputs?",
        "What bias term the model applies to adjust final scores?",
        "Why the softmax function weights change across cases?"
      ],
      "answer": "1"
    }
  ]
}
